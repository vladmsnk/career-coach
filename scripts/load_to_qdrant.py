#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ Qdrant.
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python scripts/load_to_qdrant.py
"""
import asyncio
import os
import pickle
import json
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
from uuid import UUID, uuid5, NAMESPACE_URL
from datetime import datetime

import numpy as np
import pandas as pd
from qdrant_client import QdrantClient
from qdrant_client.http.models import (
    VectorParams, Distance, PointStruct, 
    CollectionStatus, OptimizersConfigDiff
)

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò ====================
QDRANT_URL = os.getenv('QDRANT_URL', "http://localhost:6333")
COLLECTION_NAME = os.getenv('QDRANT_COLLECTION', "vacancies_tasks")
INPUT_FILE = "vacancies_with_embeddings.pickle"
UPLOAD_BATCH_SIZE = 256

# ==================== QDRANT –§–£–ù–ö–¶–ò–ò ====================

async def setup_qdrant_collection(client: QdrantClient, collection_name: str, vector_dim: int):
    """–°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é Qdrant."""
    print(f"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'...")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collections = client.get_collections()
        existing_collection = next(
            (c for c in collections.collections if c.name == collection_name), 
            None
        )
        
        if existing_collection:
            print(f"‚ö†Ô∏è  –ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –£–¥–∞–ª—è–µ–º...")
            client.delete_collection(collection_name)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
        print(f"üÜï –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é '{collection_name}' —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é {vector_dim}...")
        client.create_collection(
            collection_name=collection_name,
            vectors_config={
                "tasks": VectorParams(
                    size=vector_dim,
                    distance=Distance.COSINE
                )
            },
            optimizers_config=OptimizersConfigDiff(
                indexing_threshold=10000
            )
        )
        
        print(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
        raise

def parse_vacancy_data(row) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏—Ç –∏ –æ—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    def safe_get(field, default=""):
        value = row.get(field, default)
        if pd.isna(value):
            return default
        return str(value).strip()
    
    def parse_json_field(field, default=None):
        try:
            value = row.get(field)
            if pd.isna(value):
                return default
            if isinstance(value, str):
                return json.loads(value)
            return value
        except:
            return default
    
    # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è (–æ–Ω–∏ —É–∂–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã –∏–∑ answers_list)
    hh_id = safe_get('hh_id')
    if not hh_id:
        # Fallback: –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ URL –µ—Å–ª–∏ –µ—Å—Ç—å
        url = safe_get('url')
        if url and 'vacancy/' in url:
            hh_id = url.split('/')[-1]
        else:
            hh_id = safe_get('id')
    
    # URL –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∂–µ –≥–æ—Ç–æ–≤—ã–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
    url = safe_get('url')
    if not url and hh_id:
        url = f"https://hh.ru/vacancy/{hh_id}"
    
    # –ü–∞—Ä—Å–∏–º –∑–∞–¥–∞—á–∏ - –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —É–∂–µ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞
    tasks = row.get('tasks', [])
    if isinstance(tasks, list):
        tasks_list = tasks
        tasks_text = " ".join(str(task).strip() for task in tasks if str(task).strip())
    elif isinstance(tasks, str):
        try:
            tasks_list = json.loads(tasks)
            tasks_text = " ".join(str(task).strip() for task in tasks_list if str(task).strip())
        except:
            tasks_list = [tasks]
            tasks_text = tasks.strip()
    else:
        tasks_list = []
        tasks_text = ""
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π tasks_text –µ—Å–ª–∏ –µ—Å—Ç—å
    if 'tasks_text' in row and row['tasks_text']:
        tasks_text = safe_get('tasks_text')
    
    # –ü–∞—Ä—Å–∏–º –Ω–∞–≤—ã–∫–∏
    skills = row.get('skills', [])
    if isinstance(skills, str):
        try:
            skills = json.loads(skills)
        except:
            skills = [skills] if skills.strip() else []
    if not isinstance(skills, list):
        skills = []
    
    return {
        "hh_id": hh_id,
        "url": url,
        "title": safe_get("title"),
        "company": safe_get("company"),
        "location": safe_get("location"),
        "experience": safe_get("experience"),
        "employment_type": safe_get("employment_type"),
        "remote": safe_get("remote"),
        "posted_at": safe_get("posted_at"),
        "tasks_list": tasks_list,
        "tasks_text": tasks_text,
        "skills": skills,
        "raw_category": safe_get("category"),
        "confidence": float(row.get("confidence", 0.0)) if not pd.isna(row.get("confidence")) else 0.0,
    }

async def upload_to_qdrant(
    client: QdrantClient, 
    collection_name: str, 
    df: pd.DataFrame, 
    embeddings: np.ndarray,
    batch_size: int = UPLOAD_BATCH_SIZE
):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ Qdrant."""
    print(f"üì§ –ó–∞–≥—Ä—É–∂–∞–µ–º {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ Qdrant...")
    
    if len(df) != len(embeddings):
        raise ValueError(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: df={len(df)}, embeddings={len(embeddings)}")
    
    total_batches = (len(df) + batch_size - 1) // batch_size
    successful_uploads = 0
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, len(df))
        
        print(f"   üì¶ –ë–∞—Ç—á {batch_num + 1}/{total_batches}: –∑–∞–ø–∏—Å–∏ {start_idx}-{end_idx}")
        
        points = []
        for idx in range(start_idx, end_idx):
            row = df.iloc[idx]
            
            # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
            parsed = parse_vacancy_data(row)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID —Ç–æ—á–∫–∏
            hh_id = parsed["hh_id"]
            if not hh_id:
                print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å –±–µ–∑ hh_id –Ω–∞ –∏–Ω–¥–µ–∫—Å–µ {idx}")
                continue
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –Ω–∞ –æ—Å–Ω–æ–≤–µ hh_id
            point_id = str(uuid5(NAMESPACE_URL, hh_id))
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            vector = embeddings[idx].tolist()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É
            point = PointStruct(
                id=point_id,
                vector={"tasks": vector},
                payload=parsed
            )
            points.append(point)
        
        if not points:
            print(f"‚ö†Ô∏è  –ë–∞—Ç—á {batch_num + 1} –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á
            operation_info = client.upsert(
                collection_name=collection_name,
                points=points
            )
            successful_uploads += len(points)
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(points)} —Ç–æ—á–µ–∫ (—Å—Ç–∞—Ç—É—Å: {operation_info.status})")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞—Ç—á–∞ {batch_num + 1}: {e}")
            continue
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_uploads}/{len(df)} –∑–∞–ø–∏—Å–µ–π")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    try:
        collection_info = client.get_collection(collection_name)
        points_count = collection_info.points_count
        print(f"üìä –ó–∞–ø–∏—Å–µ–π –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {points_count}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")

async def test_search(client: QdrantClient, collection_name: str, test_embedding: np.ndarray):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ –≤ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏."""
    print(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{collection_name}'...")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞
        query_vector = test_embedding[0].tolist()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        search_result = client.search(
            collection_name=collection_name,
            query_vector=("tasks", query_vector),
            limit=3,
            with_payload=True
        )
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_result)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for i, hit in enumerate(search_result, 1):
            payload = hit.payload
            print(f"   {i}. {payload.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} ({payload.get('company', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è')})")
            print(f"      –°–∫–æ—Ä: {hit.score:.3f}, HH ID: {payload.get('hh_id', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∏—Å–∫–∞: {e}")
        return False

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Qdrant."""
    print("üöÄ –ó–ê–ì–†–£–ó–ö–ê –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –í QDRANT")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not Path(INPUT_FILE).exists():
        print(f"‚ùå –§–∞–π–ª {INPUT_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/generate_embeddings.py")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {INPUT_FILE}...")
    try:
        with open(INPUT_FILE, "rb") as f:
            data = pickle.load(f)
        
        df = data['dataframe']
        embeddings = data['embeddings']
        metadata = data['metadata']
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ:")
        print(f"   üìä –ó–∞–ø–∏—Å–µ–π: {len(df)}")
        print(f"   ü§ñ –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embeddings.shape}")
        print(f"   üìÖ –°–æ–∑–¥–∞–Ω–æ: {metadata['created_at']}")
        print(f"   üîß –ú–æ–¥–µ–ª—å: {metadata['model']}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
    if len(df) != len(embeddings):
        print(f"‚ùå –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: df={len(df)}, embeddings={len(embeddings)}")
        return
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
    print(f"üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant: {QDRANT_URL}")
    try:
        qdrant_client = QdrantClient(url=QDRANT_URL)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        collections = qdrant_client.get_collections()
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Qdrant –∑–∞–ø—É—â–µ–Ω: docker-compose up -d")
        return
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    try:
        vector_dim = embeddings.shape[1]
        await setup_qdrant_collection(qdrant_client, COLLECTION_NAME, vector_dim)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    try:
        await upload_to_qdrant(qdrant_client, COLLECTION_NAME, df, embeddings)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    test_success = await test_search(qdrant_client, COLLECTION_NAME, embeddings)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüéâ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df):,}")
    print(f"   ü§ñ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embeddings):,}")
    print(f"   üóÑÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è Qdrant: {COLLECTION_NAME}")
    print(f"   üîç –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞: {'‚úÖ –ü—Ä–æ—à–µ–ª' if test_success else '‚ùå –ù–µ –ø—Ä–æ—à–µ–ª'}")
    print(f"   üåê Qdrant Dashboard: {QDRANT_URL}/dashboard")

if __name__ == "__main__":
    asyncio.run(main())